# -*- coding: utf-8 -*-
"""TamplateMatchingCCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OaRusoBOy-fgf6gmWKfDqZsKByofrRlt
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# Buat folder templates jika belum ada
os.makedirs('templates', exist_ok=True)

# Daftar karakter yang akan dibuat templatenya
characters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')

# Ukuran template akhir
target_size = (40, 30)  # tinggi, lebar

# Path ke file font untuk angka
font_path_digits = "OCRA.ttf"
font_size = 48

def create_template(char):
    canvas_size = (100, 100)

    if char.isalpha():
        # Buat gambar putih besar pakai NumPy (untuk huruf)
        img = np.ones(canvas_size, dtype=np.uint8) * 255

        # Gambar huruf dengan OpenCV
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1.5
        thickness = 2
        (text_width, text_height), baseline = cv2.getTextSize(char, font, font_scale, thickness)
        text_x = (canvas_size[1] - text_width) // 2
        text_y = (canvas_size[0] + text_height) // 2 - baseline
        cv2.putText(img, char, (text_x, text_y), font, font_scale, (0,), thickness, lineType=cv2.LINE_AA)
    else:
        # Buat gambar putih besar pakai PIL (untuk angka)
        img_pil = Image.new('L', canvas_size, 255)
        draw = ImageDraw.Draw(img_pil)
        font = ImageFont.truetype(font_path_digits, font_size)
        bbox = draw.textbbox((0, 0), char, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        text_x = (canvas_size[0] - text_width) // 2
        text_y = (canvas_size[1] - text_height) // 2
        draw.text((text_x, text_y), char, font=font, fill=0)
        img = np.array(img_pil)

    # Crop area karakter
    coords = cv2.findNonZero(255 - img)
    if coords is not None:
        x, y, w, h = cv2.boundingRect(coords)
        char_crop = img[y:y+h, x:x+w]
    else:
        char_crop = img

    # Resize dan tempel ke canvas target
    h, w = char_crop.shape
    scale = min(target_size[0]/h, target_size[1]/w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(char_crop, (new_w, new_h), interpolation=cv2.INTER_NEAREST)

    canvas = np.ones(target_size, dtype=np.uint8) * 255
    x_offset = (target_size[1] - new_w) // 2
    y_offset = (target_size[0] - new_h) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized

    return canvas

# Simpan semua template
for char in characters:
    tmpl_img = create_template(char)
    Image.fromarray(tmpl_img).save(f'templates/{char}.png')

from google.colab import files
import cv2
import numpy as np
import matplotlib.pyplot as plt

import os
import cv2
import numpy as np

def load_templates(template_folder):
    templates = {}
    for filename in os.listdir(template_folder):
        if filename.endswith(".png"):
            label = os.path.splitext(filename)[0]
            img = cv2.imread(os.path.join(template_folder, filename), cv2.IMREAD_GRAYSCALE)
            _, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
            templates[label] = img_bin
    return templates

def match_char_template(char_img, templates):
    best_score = -1
    best_char = None

    char_img_resized = cv2.resize(char_img, (40, 40))  # Samakan ukuran ke template
    _, char_img_resized = cv2.threshold(char_img_resized, 127, 255, cv2.THRESH_BINARY)

    for label, template in templates.items():
        template_resized = cv2.resize(template, (40, 40))
        result = cv2.matchTemplate(char_img_resized, template_resized, cv2.TM_CCOEFF_NORMED)
        _, score, _, _ = cv2.minMaxLoc(result)

        if score > best_score:
            best_score = score
            best_char = label

    return best_char

def recognize_text_from_segments(char_segments, templates):
    recognized = ""
    for char_img in char_segments:
        matched = match_char_template(char_img, templates)
        if matched:
            recognized += matched
    return recognized

# 2. Upload file
uploaded = files.upload()  # Upload ktp_sample.jpg

# 3. Baca gambar dan preprocessing
# Get the uploaded file name
uploaded_file_name = list(uploaded.keys())[0]
print(f"Uploaded file name: {uploaded_file_name}")  # Print the file name to verify

img = cv2.imread(uploaded_file_name)


# Check if the image was loaded successfully
if img is None:
    print("Error: Could not load the image. Please check the file path.")
else:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)
    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 2)

    plt.imshow(thresh, cmap='gray')
    plt.title('Preprocessed Image')
    plt.axis('off')
    plt.show()

img = cv2.imread(uploaded_file_name)

# Ubah ke grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Kurangi noise sambil pertahankan edge
blur = cv2.bilateralFilter(gray, 11, 17, 17)

# Threshold Otsu (lebih cocok dari adaptive untuk citra dokumen)
_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# Hapus noise kecil dengan morphological opening
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)

# Tampilkan hasil akhir preprocessing
plt.figure(figsize=(8, 6))
plt.imshow(opened, cmap='gray')
plt.title("Preprocessed Image")
plt.axis('off')
plt.show()

# Baca gambar
img = cv2.imread(uploaded_file_name)
# (NIK JUGA)
# Tentukan koordinat cropping (x, y, width, height)
# Misalnya, crop dari titik (50, 50) dengan ukuran 300x400
x, y, w, h = 20, 90, 450, 400
cropped_img = img[y:y+h, x:x+w]

# Ubah ke grayscale
gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)

# Kurangi noise sambil pertahankan edge
blur = cv2.bilateralFilter(gray, 11, 17, 17)

# Threshold Otsu
_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# Bersihkan noise kecil
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)

# Hapus noise kecil dengan morphological opening
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
opened = cv2.morphologyEx(opened, cv2.MORPH_OPEN, kernel, iterations=1)

# Tampilkan hasil akhir preprocessing
plt.figure(figsize=(8, 6))
plt.imshow(opened, cmap='gray')
plt.title("Preprocessed Image")
plt.axis('off')
plt.show()

# 1. Morphological dilation agar karakter menyatu jadi blok kata
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 3))  # horizontal emphasis
dilated = cv2.dilate(thresh, kernel, iterations=1)

# 2. CCA pada hasil dilasi
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dilated, connectivity=8)

# 3. Filter dan simpan komponen yang layak
components = []
for i in range(1, num_labels):
    x, y, w, h, area = stats[i]

    # Filter ukuran minimal dan proporsi yang lebih mendekati teks
    if w > 30 and h > 10 and area > 100 and (w / h) < 10:  # lebih mendekati ukuran teks
        components.append((x, y, w, h))

# 4. Visualisasi bounding box di atas gambar threshold
img_box = cv2.cvtColor(thresh.copy(), cv2.COLOR_GRAY2BGR)
for (x, y, w, h) in components:
    cv2.rectangle(img_box, (x, y), (x+w, y+h), (0, 255, 0), 1)
plt.figure(figsize=(8, 10))
plt.imshow(img_box)
plt.title("Bounding Box Rapi di Gambar Hitam-Putih")
plt.axis('off')
plt.show()

# Buat salinan warna dari citra threshold
img_numbered = cv2.cvtColor(thresh.copy(), cv2.COLOR_GRAY2BGR)

for idx, (x, y, w, h) in enumerate(components):
    # Gambar bounding box
    cv2.rectangle(img_numbered, (x, y), (x+w, y+h), (0, 255, 0), 1)

    # Hitung posisi tengah dari bounding box
    text_x = x + w // 4
    text_y = y + h // 2

    # Tambahkan outline hitam untuk kontras (shadow)
    cv2.putText(img_numbered, str(idx), (text_x + 1, text_y + 1),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)

    # Tambahkan teks dengan warna terang (misal putih kehijauan)
    cv2.putText(img_numbered, str(idx), (text_x, text_y),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (144, 238, 144), 2, cv2.LINE_AA)

# Tampilkan hasil
plt.figure(figsize=(8, 6))
plt.imshow(img_numbered)
plt.title("Nomor Komponen Bounding Box (Diperbaiki)")
plt.axis('off')
plt.show()

# 4. Ekstraksi ROI berdasarkan komponen hasil CCA
# (Bantu visualisasi dan ambil 4 area: nama, alamat, jenis kelamin, pekerjaan)

# Sort dari atas ke bawah
components_sorted = sorted(components, key=lambda comp: comp[1])  # sort by Y

# Misal ambil secara manual berdasarkan hasil visual:
# [Gantilah indeks berikut jika urutan bounding box tidak sesuai]
nik_box         = components_sorted[0]
nama_box        = components_sorted[3]
alamat_box      = components_sorted[10]
pekerjaan_box   = components_sorted[22]

def enhance_roi(roi):
    # Perbesar ukuran
    roi = cv2.resize(roi, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)

    # Median blur untuk mengurangi noise
    roi = cv2.medianBlur(roi, 3)

    # Thresholding ulang
    _, roi_bin = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Inversi agar teks menjadi hitam di atas putih
    roi_inverted = cv2.bitwise_not(roi_bin)

    return roi_inverted

def extract_text_area(box, image, label):
    x, y, w, h = box
    roi = image[y:y+h, x:x+w]

    # Tingkatkan kualitas ROI
    roi_enhanced = enhance_roi(roi)

    # Visualisasi
    plt.imshow(roi_enhanced, cmap='gray')
    plt.title(label)
    plt.axis('off')
    plt.show()

    return roi_enhanced
nik_img = extract_text_area(nik_box, thresh, "NIK")
nama_img = extract_text_area(nama_box, thresh, "Nama")
alamat_img = extract_text_area(alamat_box, thresh, "Alamat")
pekerjaan_img = extract_text_area(pekerjaan_box, thresh, "Pekerjaan")

def segment_characters_projection(roi_img):
    # Thresholding dan inversi agar teks jadi hitam (0), background putih (255)
    _, thresh = cv2.threshold(roi_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    thresh = 255 - thresh

    # Hitung jumlah piksel hitam di setiap kolom
    vertical_sum = np.sum(thresh == 0, axis=0)

    # Identifikasi area dengan piksel hitam (kemungkinan karakter)
    threshold = 3  # bisa disesuaikan
    in_char = False
    start_idx = 0
    char_regions = []

    for i, val in enumerate(vertical_sum):
        if val > threshold and not in_char:
            start_idx = i
            in_char = True
        elif val <= threshold and in_char:
            end_idx = i
            in_char = False
            if end_idx - start_idx > 2:  # minimal lebar karakter
                char_regions.append((start_idx, end_idx))

    characters = []
    boxed_img_color = cv2.cvtColor(roi_img, cv2.COLOR_GRAY2BGR)

    for (start_x, end_x) in char_regions:
        char_img = roi_img[:, start_x:end_x]
        characters.append((start_x, char_img))
        # Gambar bounding box
        cv2.rectangle(boxed_img_color, (start_x, 0), (end_x, roi_img.shape[0]), (0, 0, 255), 1)

    # Urutkan dari kiri ke kanan
    characters = sorted(characters, key=lambda c: c[0])

    # Visualisasi ROI dengan bounding box
    plt.figure(figsize=(10, 4))
    plt.imshow(boxed_img_color, cmap='gray')
    plt.title("ROI dengan Bounding Box Karakter (Projection Profile)")
    plt.axis('off')
    plt.show()

    # Tampilkan masing-masing karakter
    plt.figure(figsize=(10, 4))
    for i, (_, char) in enumerate(characters):
        plt.subplot(1, len(characters), i+1)
        plt.imshow(char, cmap='gray')
        plt.axis('off')
    plt.suptitle("Hasil Segmentasi Karakter (Projection)")
    plt.show()

    return [char for (_, char) in characters]

nik_img = extract_text_area(nik_box, thresh, "NIK")
nama_img = extract_text_area(nama_box, thresh, "Nama")
alamat_img = extract_text_area(alamat_box, thresh, "Alamat")
# jk_img = extract_text_area(jk_box, thresh, "Jenis Kelamin")
pekerjaan_img = extract_text_area(pekerjaan_box, thresh, "Pekerjaan")

def split_wide_character(char_img, max_char_width=30):
    """Pisahkan karakter lebar berdasarkan vertical projection"""
    _, bin_img = cv2.threshold(char_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    bin_img = 255 - bin_img  # teks hitam

    proj = np.sum(bin_img == 0, axis=0)
    cut_indices = []

    threshold = 2
    in_gap = False
    for i in range(1, len(proj)):
        if proj[i] <= threshold and not in_gap:
            cut_indices.append(i)
            in_gap = True
        elif proj[i] > threshold:
            in_gap = False

    parts = []
    last = 0
    for i in cut_indices:
        if i - last > 3:  # Hindari potongan terlalu kecil
            parts.append(char_img[:, last:i])
            last = i
    if last < char_img.shape[1] - 2:
        parts.append(char_img[:, last:])

    return parts if len(parts) >= 2 else [char_img]

def segment_characters_auto_split(img_roi):
    # Preprocess
    _, bin_img = cv2.threshold(img_roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    bin_img = 255 - bin_img

    # Morph: erode untuk bantu pisah
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    bin_img = cv2.erode(bin_img, kernel, iterations=1)

    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    char_regions = []
    for c in contours:
        x, y, w, h = cv2.boundingRect(c)
        aspect_ratio = h / float(w + 1e-5)

        # Hilangkan garis vertikal noise
        if w < 4 and aspect_ratio > 3 and h < 30:
            continue

        if h > 10 and w > 5:
            char = img_roi[y:y+h, x:x+w]
            if w > 35:
                parts = split_wide_character(char)
                for i, p in enumerate(parts):
                    char_regions.append((x + i, p))
            else:
                char_regions.append((x, char))

    # Urutkan berdasarkan X
    char_regions = sorted(char_regions, key=lambda tup: tup[0])
    char_images = [char for (_, char) in char_regions]

    # Visualisasi karakter
    plt.figure(figsize=(12, 3))
    for i, char in enumerate(char_images):
        plt.subplot(1, len(char_images), i+1)
        plt.imshow(char, cmap='gray')
        plt.axis('off')
    plt.suptitle("Karakter Tersegmentasi (Auto Split)")
    plt.show()

    return char_images

chars_nik = segment_characters_auto_split(nik_img)
chars_nama = segment_characters_auto_split(nama_img)
chars_alamat = segment_characters_auto_split(alamat_img)
chars_jk = segment_characters_auto_split(jk_img)
chars_pekerjaan = segment_characters_auto_split(pekerjaan_img)

def segment_characters(roi_img):
    # Thresholding (tanpa invers)
    _, roi_bin = cv2.threshold(roi_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Connected Components
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(255 - roi_bin, connectivity=8)

    characters = []
    boxed_img = roi_img.copy()
    boxed_img_color = cv2.cvtColor(boxed_img, cv2.COLOR_GRAY2BGR)

    for i in range(1, num_labels):  # Skip background
        x, y, w, h, area = stats[i]
        if area > 50 and h > 10:
            char_img = roi_img[y:y+h, x:x+w]
            characters.append((x, char_img))

            # Gambar bounding box (warna merah)
            cv2.rectangle(boxed_img_color, (x, y), (x + w, y + h), (255, 0, 0), 1)

    # Urutkan dari kiri ke kanan
    characters = sorted(characters, key=lambda c: c[0])

    # Tampilkan ROI dengan bounding box
    plt.figure(figsize=(8, 6))
    plt.imshow(boxed_img_color)
    plt.title("ROI dengan Bounding Box Karakter")
    plt.axis('off')
    plt.show()

    # Tampilkan potongan karakter
    plt.figure(figsize=(8, 6))
    for i, (_, char) in enumerate(characters):
        plt.subplot(1, len(characters), i+1)
        plt.imshow(char, cmap='gray')
        plt.axis('off')
    plt.suptitle("Hasil Segmentasi Karakter")
    plt.show()

    return [char for (_, char) in characters]

# Segmentasi karakter dari masing-masing ROI
chars_nik = segment_characters(nik_img)
chars_nama = segment_characters(nama_img)
chars_alamat = segment_characters(alamat_img)
# chars_jk = segment_characters(jk_img)
chars_pekerjaan = segment_characters(pekerjaan_img)

# 6. Eksekusi OCR per bidang data KTP
templates = load_templates('/content/templates')  # Specify the correct path to your templates directory

nik_text = recognize_text_from_segments(chars_nik, templates)
nama_text = recognize_text_from_segments(chars_nama, templates)
alamat_text = recognize_text_from_segments(chars_alamat, templates)
pekerjaan_text = recognize_text_from_segments(chars_pekerjaan, templates)

print("Hasil Ekstraksi:")
print("NIK            :", nik_text)
print("Nama           :", nama_text)
print("Alamat         :", alamat_text)
print("Pekerjaan      :", pekerjaan_text)